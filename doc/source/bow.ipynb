{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the Bag-of-Words representation\n",
    "\n",
    "The [bow module](api.rst#tmtoolkit-bow) in tmtoolkit contains several functions for working with Bag-of-Words (BoW) representations of documents. It's divided into two sub-modules: [bow.bow_stats](api.rst#module-tmtoolkit.bow.bow_stats) and [bow.dtm](api.rst#module-tmtoolkit.bow.dtm). The former implements several statistics and transformations for BoW representations, the latter contains functions to create and convert sparse or dense document-term matrices (DTMs).\n",
    "\n",
    "Most of the functions in both sub-modules accept and/or return DTMs. The [previous chapter](preprocessing.iypnb) contained a section about what *sparse* DTMs are and [how they can be generated with tmtoolkit](preprocessing.iypnb#Generating-a-sparse-document-term-matrix-(DTM))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example document-term matrix\n",
    "\n",
    "Before we start with the [bow.dtm](api.rst#module-tmtoolkit.bow.dtm) module, we will generate a sparse DTM from a small example corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(20191113)   # to make the sampling reproducible\n",
    "\n",
    "from tmtoolkit.corpus import Corpus\n",
    "\n",
    "corpus = Corpus.from_builtin_corpus('english-NewsArticles').sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a sample document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merkel: 'Only if Europe is doing well, will Germany be doing well'\n",
      "\n",
      "Ahead of meeting her fellow European leaders at a summit in Brussels, German Chancellor Angela Merkel has reiterated her government's call for unity in the EU.\n"
     ]
    }
   ],
   "source": [
    "print(corpus['NewsArticles-2058'][:227])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We employ a preprocessing pipeline that removes a lot of information from our original data in order to obtain a very condensed DTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool { background: #DDDD99; }\n",
       ".datatable .obj  { background: #565656; }\n",
       ".datatable .int  { background: #5D9E5D; }\n",
       ".datatable .real { background: #4040CC; }\n",
       ".datatable .str  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n",
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>doc</th><th>position</th><th>token</th><th>meta_pos</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>NewsArticles-119</td><td>0</td><td>nhs</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>NewsArticles-119</td><td>1</td><td>nhs</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>NewsArticles-119</td><td>2</td><td>pledge</td><td>NN</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>NewsArticles-119</td><td>3</td><td>prime</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>NewsArticles-119</td><td>4</td><td>minister</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>NewsArticles-119</td><td>5</td><td>david</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>NewsArticles-119</td><td>6</td><td>cameron</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>NewsArticles-119</td><td>7</td><td>theresa</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>NewsArticles-119</td><td>8</td><td>may</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>NewsArticles-119</td><td>9</td><td>government</td><td>NN</td></tr>\n",
       "    <tr><td class='row_index'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td></tr>\n",
       "    <tr><td class='row_index'>919</td><td>NewsArticles-3665</td><td>344</td><td>author</td><td>NN</td></tr>\n",
       "    <tr><td class='row_index'>920</td><td>NewsArticles-3665</td><td>345</td><td>al</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>921</td><td>NewsArticles-3665</td><td>346</td><td>jazeera</td><td>NNP</td></tr>\n",
       "    <tr><td class='row_index'>922</td><td>NewsArticles-3665</td><td>347</td><td>editorial</td><td>NN</td></tr>\n",
       "    <tr><td class='row_index'>923</td><td>NewsArticles-3665</td><td>348</td><td>policy</td><td>NN</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>924 rows &times; 4 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.preprocess import TMPreproc\n",
    "\n",
    "preproc = TMPreproc(corpus)\n",
    "preproc.pos_tag() \\\n",
    "    .lemmatize() \\\n",
    "    .filter_for_pos('N') \\\n",
    "    .tokens_to_lowercase() \\\n",
    "    .remove_special_chars_in_tokens() \\\n",
    "    .clean_tokens(remove_shorter_than=2) \\\n",
    "    .remove_common_tokens(5, absolute=True) # remove tokens that occur in all documents\n",
    "preproc.tokens_datatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 530)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.n_docs, len(preproc.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch the document labels and vocabulary and convert them to NumPy arrays, because such arrays allow advanced indexing methods such as boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NewsArticles-119', 'NewsArticles-1206', 'NewsArticles-2058',\n",
       "       'NewsArticles-3016', 'NewsArticles-3665'], dtype='<U17')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_labels = np.array(preproc.doc_labels)\n",
    "doc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abuse', 'access', 'accession', 'accusation', 'act', 'addition',\n",
       "       'address', 'addressing', 'administration', 'affiliation'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(preproc.vocabulary)\n",
    "vocab[:10]  # only showing the first 10 tokens here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fetch the sparse DTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x530 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 596 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = preproc.dtm\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a sparse DTM `dtm`, a list of document labels `doc_labels` that represent the rows of the DTM and a list of vocabulary tokens `vocab` that represent the columns of the DTM. We will use this data for the remainder of the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `bow.dtm` module\n",
    "\n",
    "This module is quite small. There are two functions to convert a DTM to a [datatable](https://github.com/h2oai/datatable/) or [DataFrame](https://pandas.pydata.org/): [dtm_to_datatable()](api.rst#tmtoolkit.bow.dtm.dtm_to_datatable) and [dtm_to_dataframe()](api.rst#tmtoolkit.bow.dtm.dtm_to_dataframe). Note that the generated datatable or DataFrame is *dense*, i.e. it uses up (much) more memory than the input DTM.\n",
    "\n",
    "Let's generate a datatable via [dtm_to_datatable()](api.rst#tmtoolkit.bow.dtm.dtm_to_datatable) from our DTM, the document labels and the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>_doc</th><th>abuse</th><th>access</th><th>accession</th><th>accusation</th><th>act</th><th>addition</th><th>address</th><th>addressing</th><th>administration</th><th class='vellipsis'>&hellip;</th><th>year</th><th>yes</th><th>york</th><th>yucel</th><th>yucellast</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td></td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>NewsArticles-119</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>NewsArticles-1206</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>NewsArticles-2058</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td class=vellipsis>&hellip;</td><td>2</td><td>1</td><td>0</td><td>1</td><td>1</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>NewsArticles-3016</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td class=vellipsis>&hellip;</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>NewsArticles-3665</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td class=vellipsis>&hellip;</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>5 rows &times; 531 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.dtm import dtm_to_datatable\n",
    "\n",
    "dtm_to_datatable(dtm, doc_labels, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a row `_doc` with the document labels was created and that the vocabulary tokens become the column names. [dtm_to_dataframe()](api.rst#tmtoolkit.bow.dtm.dtm_to_dataframe) works the same way.\n",
    "\n",
    "You can combine tmtoolkit with [Gensim](https://radimrehurek.com/gensim/). The `bow.dtm` module provides several functions to convert data between both packages:\n",
    "\n",
    "- [dtm_and_vocab_to_gensim_corpus_and_dict()](api.rst#tmtoolkit.bow.dtm.dtm_and_vocab_to_gensim_corpus_and_dict): converts a (sparse) DTM and a vocabulary list to a *Gensim Corpus* and *Gensim Dictionary*\n",
    "- [dtm_to_gensim_corpus()](api.rst#tmtoolkit.bow.dtm.dtm_to_gensim_corpus): convert a (sparse) DTM only to a *Gensim Corpus*\n",
    "- [gensim_corpus_to_dtm()](api.rst#tmtoolkit.bow.dtm.gensim_corpus_to_dtm): converts a *Gensim Corpus* object to a sparse DTM in COO format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `bow.bow_stats` module\n",
    "\n",
    "This module provides several statistics and transformations for sparse or dense DTMs.\n",
    "\n",
    "### Document lengths, document and term frequencies, token co-occurrences\n",
    "\n",
    "Let's start with the [doc_lengths()](api.rst#tmtoolkit.bow.bow_stats.doc_lengths) function, which simply gives the number of tokens per document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 36,  37, 338, 164, 349])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import doc_lengths\n",
    "\n",
    "doc_lengths(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned array is aligned to the document labels `doc_labels` so we can see that the last document, \"NewsArticles-3665\", is the one with the most tokens. Or to do it computationally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NewsArticles-3665'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_labels[doc_lengths(dtm).argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [doc_frequencies()](api.rst#tmtoolkit.bow.bow_stats.doc_frequencies) returns how often each token in the vocabulary occurs at least *n* times per document. You can control *n* per parameter `min_val` which is set to `1` by default. The returned array is aligned with the vocabulary. Here, we calculate the document frequency with `min_val=1`, extract the maximum document frequency and see which of tokens in the `vocab` array reach the maximum document frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, array(['minister'], dtype='<U20'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import doc_frequencies\n",
    "\n",
    "df = doc_frequencies(dtm)\n",
    "max_df = df.max()\n",
    "max_df, vocab[df == max_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the maximum document frequency is 4 and only the token \"minister\" reaches that document frequency. This means only \"minister\" is mentioned across 4 documents at least once (because `min_val` is `1`). Remember that during preprocessing, we removed all tokens that occur across *all* five documents, hence there can't be a vocabulary token with a document frequency of 5.\n",
    "\n",
    "Let's see which vocabulary tokens occur within a single document at least 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['candidate', 'eu', 'macron', 'medium', 'merkel', 'refugee'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = doc_frequencies(dtm, min_val=10)\n",
    "vocab[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codoc_frequencies\n",
    "term_frequencies\n",
    "\n",
    "sorted_terms\n",
    "sorted_terms_data_table\n",
    "\n",
    "tfidf\n",
    "\n",
    "tf_proportions\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
