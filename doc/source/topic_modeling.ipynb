{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling\n",
    "\n",
    "The [topicmod module](api.rst#module-tmtoolkit.topicmod) offers a wide range of tools to facilitate [topic modeling](https://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext) with Python. This chapter will introduce the following techniques: \n",
    "\n",
    "TODO (link this)\n",
    "TODO model convergence\n",
    "\n",
    "- [parallel topic model computation for different copora and/or parameter sets](#Computing-topic-models-in-parallel)\n",
    "- evaluation of topic models (including finding the \"optimal\" number of topics)\n",
    "- common statistics for topic models\n",
    "- export of topic models and summaries to different file formats\n",
    "- visualization of topic models\n",
    "\n",
    "## An example document-term matrix\n",
    "\n",
    "tmtoolkit supports topic models that are computed from document-term matrices (DTMs). Just as in the previous chapter, we will at first generate a DTM. However, this time the sample will be bigger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(20191120)   # to make the sampling reproducible\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "from tmtoolkit.corpus import Corpus\n",
    "\n",
    "corpus = Corpus.from_builtin_corpus('english-NewsArticles').sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also now generate two DTMs, because we later want to show how you can compute topic models for two different DTMs in parallel. At first, we to some general preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TMPreproc [100 documents]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.preprocess import TMPreproc\n",
    "\n",
    "preproc = TMPreproc(corpus)\n",
    "preproc.pos_tag() \\\n",
    "    .lemmatize() \\\n",
    "    .tokens_to_lowercase() \\\n",
    "    .remove_special_chars_in_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we at first apply more \"relaxed\" cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 846)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_bigger = preproc.copy() \\\n",
    "    .clean_tokens(remove_shorter_than=2) \\\n",
    "    .remove_common_tokens(df_threshold=0.95) \\\n",
    "    .remove_uncommon_tokens(df_threshold=0.05)\n",
    "\n",
    "preproc_bigger.n_docs, preproc_bigger.vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another copy of `preproc` will apply more aggressive cleaning and hence in a smaller vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 149)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_smaller = preproc.copy() \\\n",
    "    .filter_for_pos('N') \\\n",
    "    .clean_tokens(remove_numbers=True, remove_shorter_than=2) \\\n",
    "    .remove_common_tokens(df_threshold=0.9) \\\n",
    "    .remove_uncommon_tokens(df_threshold=0.1)\n",
    "\n",
    "del preproc\n",
    "\n",
    "preproc_smaller.n_docs, preproc_smaller.vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the document labels, vocabulary arrays and DTMs for both versions now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NewsArticles-1032', 'NewsArticles-1036', 'NewsArticles-104',\n",
       "       'NewsArticles-1043', 'NewsArticles-1048', 'NewsArticles-1090',\n",
       "       'NewsArticles-1126', 'NewsArticles-113', 'NewsArticles-1137',\n",
       "       'NewsArticles-1141'], dtype='<U17')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_labels are the same for both\n",
    "\n",
    "doc_labels = np.array(preproc_bigger.doc_labels)\n",
    "doc_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bg = np.array(preproc_bigger.vocabulary)\n",
    "vocab_sm = np.array(preproc_smaller.vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<100x846 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 10356 stored elements in Compressed Sparse Row format>,\n",
       " <100x149 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 2482 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_bg = preproc_bigger.dtm\n",
    "dtm_sm = preproc_smaller.dtm\n",
    "\n",
    "del preproc_bigger, preproc_smaller  # don't need these any more\n",
    "\n",
    "dtm_bg, dtm_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two sparse DTMs `dtm_bg` (from the bigger preprocessed data) and `dtm_sm` (from the smaller preprocessed data), a list of document labels `doc_labels` that represent the rows of both DTMs and vocabulary arrays `vocab_bg` and `vocab_sm` that represent the columns of the respective DTMs. We will use this data for the remainder of the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing topic models in parallel\n",
    "\n",
    "tmtoolkit allows to compute topic models in parallel, making use of all processor cores in your machine. Parallelization can be done per input DTM, per hyperparameter set and as combination of both. Hyperparameters control the number of topics and their \"granularity\". We will later have a look at the role of hyperparameters and how to find an optimal combination for a given dataset with the means of topic model evaluation.\n",
    "\n",
    "For now, we will concentrate on computing the topic models for both of our two DTMs in parallel. tmtoolkit supports three very popular packages for topic modeling, which provide the work of actually computing the model from the input matrix. They can all be accessed in separate sub-modules of the [topicmod module](api.rst#module-tmtoolkit.topicmod):\n",
    "\n",
    "- [topicmod.tm_lda](api.html#module-tmtoolkit.topicmod.tm_lda) provides an interface for the [lda](https://lda.readthedocs.io/en/latest/) package\n",
    "- [topicmod.tm_sklearn](api.html#module-tmtoolkit.topicmod.tm_sklearn) provides an interface for the [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) package\n",
    "- [topicmod.tm_gensim](api.html#module-tmtoolkit.topicmod.tm_gensim) provides an interface for the [Gensim](https://radimrehurek.com/gensim/) package\n",
    "\n",
    "Each of these sub-modules offer at least two functions that work with the respective package: `compute_models_parallel()` for general parallel model computation and `evaluate_topic_models()` for parallel model computation and evaluation (discussed later). For now, we want to compute two models in parallel with the [lda](https://lda.readthedocs.io/en/latest/) package and hence use [compute_models_parallel()](api.rst#tmtoolkit.topicmod.tm_lda.compute_models_parallel) from [topicmod.tm_lda](api.html#module-tmtoolkit.topicmod.tm_lda).\n",
    "\n",
    "We need to provide two things for this function: First, the input matrices as a dict that maps labels to the respective DTMs. Second, hyperparameters to use for the model computations. Note that each topic modeling package has different hyperparameters and you should refer to their documentation in order to find out, which hyperparameters you can provide. For lda, we set the number of topics `n_topics` to 10 and the number of iterations for the Gibbs sampling process `n_iter` to 1000. We always want to use the same hyperparameters, so we pass these as `constant_parameters`. If we wanted to create models for a whole range of parameters, e.g. for different numbers of topics, we could provide `varying_parameters`. We will check this out later when we evaluate topic models.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Note that for proper topic modeling, we shouldn't just set the number of topics, but try to find it out via evaluation methods. We should also check if the algorithm converged using the provided likelihood estimations. We will do both later on, but now focus on `compute_models_parallel()`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'smaller': [({'n_topics': 10, 'n_iter': 1000},\n",
       "               <lda.lda.LDA at 0x7fc12c740898>)],\n",
       "             'bigger': [({'n_topics': 10, 'n_iter': 1000},\n",
       "               <lda.lda.LDA at 0x7fc12c740278>)]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n",
    "\n",
    "# suppress the \"INFO\" messages and warnings from lda\n",
    "logger = logging.getLogger('lda')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set data to use\n",
    "dtms = {\n",
    "    'bigger': dtm_bg,\n",
    "    'smaller': dtm_sm\n",
    "}\n",
    "\n",
    "# and fixed hyperparameters\n",
    "lda_params = {\n",
    "    'n_topics': 10,\n",
    "    'n_iter': 1000\n",
    "}\n",
    "\n",
    "models = compute_models_parallel(dtms, constant_parameters=lda_params)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, two models were created. These can be accessed via the labels that we used to define the `dtm` dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'n_topics': 10, 'n_iter': 1000}, <lda.lda.LDA at 0x7fc12c740898>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['smaller']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for each input DTM, we get a list of 2-tuples. The first element in each tuple is a dict that represents the hyperparameters that were used to compute the model, the second element is actual topic model (the `<lda.lda.LDA ...>` object). This structure looks a bit complex, but this is because it also supports varying parameters. Since we only have one fixed set of hyperparameters per DTM, we only have a list of length 1 for each DTM.\n",
    "\n",
    "We will now access the models and print the top words per topic by using [print_ldamodel_topic_words()](api.rst#tmtoolkit.topicmod.model_io.print_ldamodel_topic_words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_1\n",
      "> #1. people (0.137050)\n",
      "> #2. country (0.101592)\n",
      "> #3. year (0.075717)\n",
      "topic_2\n",
      "> #1. election (0.088436)\n",
      "> #2. leader (0.088436)\n",
      "> #3. party (0.088436)\n",
      "topic_3\n",
      "> #1. germany (0.094707)\n",
      "> #2. percent (0.088910)\n",
      "> #3. year (0.059924)\n",
      "topic_4\n",
      "> #1. mr (0.209053)\n",
      "> #2. investigation (0.090129)\n",
      "> #3. statement (0.082922)\n",
      "topic_5\n",
      "> #1. us (0.129454)\n",
      "> #2. report (0.127012)\n",
      "> #3. russia (0.112359)\n",
      "topic_6\n",
      "> #1. force (0.111813)\n",
      "> #2. syria (0.089941)\n",
      "> #3. source (0.077790)\n",
      "topic_7\n",
      "> #1. trump (0.202530)\n",
      "> #2. president (0.104168)\n",
      "> #3. house (0.090667)\n",
      "topic_8\n",
      "> #1. china (0.198046)\n",
      "> #2. company (0.123237)\n",
      "> #3. market (0.092433)\n",
      "topic_9\n",
      "> #1. day (0.117525)\n",
      "> #2. child (0.102199)\n",
      "> #3. family (0.084319)\n",
      "topic_10\n",
      "> #1. police (0.164607)\n",
      "> #2. attack (0.119975)\n",
      "> #3. officer (0.103239)\n"
     ]
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n",
    "\n",
    "model_sm = models['smaller'][0][1]\n",
    "print_ldamodel_topic_words(model_sm.topic_word_, vocab_sm, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_1\n",
      "> #1. police (0.081255)\n",
      "> #2. officer (0.055464)\n",
      "> #3. man (0.043858)\n",
      "topic_2\n",
      "> #1. trump (0.086968)\n",
      "> #2. president (0.053012)\n",
      "> #3. house (0.048043)\n",
      "topic_3\n",
      "> #1. say (0.049042)\n",
      "> #2. year (0.033772)\n",
      "> #3. one (0.029955)\n",
      "topic_4\n",
      "> #1. china (0.058659)\n",
      "> #2. company (0.048884)\n",
      "> #3. market (0.029333)\n",
      "topic_5\n",
      "> #1. people (0.033917)\n",
      "> #2. country (0.027558)\n",
      "> #3. make (0.025136)\n",
      "topic_6\n",
      "> #1. would (0.044348)\n",
      "> #2. leader (0.026519)\n",
      "> #3. new (0.025605)\n",
      "topic_7\n",
      "> #1. say (0.145526)\n",
      "> #2. report (0.036203)\n",
      "> #3. mr (0.020999)\n",
      "topic_8\n",
      "> #1. people (0.037668)\n",
      "> #2. force (0.037668)\n",
      "> #3. syria (0.030300)\n",
      "topic_9\n",
      "> #1. election (0.068604)\n",
      "> #2. vote (0.054450)\n",
      "> #3. germany (0.053361)\n",
      "topic_10\n",
      "> #1. us (0.078872)\n",
      "> #2. russian (0.052268)\n",
      "> #3. russia (0.044667)\n"
     ]
    }
   ],
   "source": [
    "model_bg = models['bigger'][0][1]\n",
    "print_ldamodel_topic_words(model_bg.topic_word_, vocab_bg, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for single dtm, varying n_iter -> model convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
